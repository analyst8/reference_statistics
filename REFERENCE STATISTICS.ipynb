{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressions\n",
    "- Can be linear (simple or multiple) or logistic (simple or multiple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "What is it?\n",
    "- In simple linear regression a single independent variable is used to predict the value of a dependent variable. In multiple linear regression two or more independent variables are used to predict the value of a dependent variable.\n",
    "- Ordinary least squares (OLS) is a type of linear least squares method for estimating the unknown parameters in a linear regression model.\n",
    "- The dependent variable must be measured on a continuous measurement scale (e.g. 0-100 test score) and the independent variable(s) can be measured on either a categorical (e.g. male versus female) or continuous measurement scale.\n",
    "- Each point is best average for that point. It minimizes the sum of squared errors. \n",
    "\n",
    "- Nearest Neighbour - Can be used for regression or classification.\n",
    "When not a lot of points, it uses a range of points (a width or slice of x values) that are close to the point so can average them. Good for low number of variables (or dimensions) and at least a moderate number of points. Not good for high dimensions since need to average out much larger slice of points thus no longer local estimate. So use flexible regression model instead but becomes harder to understand.\n",
    "- problems with correlated co-efficients is that the variance tends to increase, sometimes dramatically. Interpretations become hazardous.. Claims of causality should be avoided for obseravational data.\n",
    "- If want to make a causal statement about one of the a variable then have to keep that varialbe fixed while changing the others.\n",
    "\n",
    "Questions to ask:\n",
    "- Is at least one of the predictors useful in predicting the response?\n",
    "- Are all or only subset useful?\n",
    "- How well does the model fit the data?\n",
    "- How accurate is the prediction?\n",
    "\n",
    "- look at residual standard error, R squared, F statistic\n",
    "- most direct approach is called \"all subset\" OR \"best subsets\" where we compute the least square fit for all possible subsets and then choose between them based on some criterion that balances training error with model size\n",
    "\n",
    "Model Selection approaches \n",
    "- forward selection = start with no predictors and add predictors one at a time starting with the predictor that results in the lowest residual sum squares. Keep adding until some stopping rule is satisfied (eg. when all remaining variables have a p value above some threshold)\n",
    "- backward selection = start with all predictors and remove one at a time starting with the predictor that is least significant. Stop when all remaining variable have a significant p-value defined by some significance threshold.\n",
    "- Mallow's Cp\n",
    "- Akaike information criterion (AIC)\n",
    "- Bayesian information criterion (BIC)\n",
    "- adjusted R squared\n",
    "- cross validation (CV)\n",
    "\n",
    "Is the variable quantitative or qualitative?\n",
    "- qualitative takes discrete variables\n",
    "- if 2 levels, make one dummy variable. If 3 levels, make two dummy variable and so on.\n",
    "\n",
    "- for interactions, add the product of the 2 variables and calculate in equation to see if significant eg. tv and radio ads may have a synergistic affect for sales\n",
    "- for interaction of qualitative and quantitative variable, the intercept just changes\n",
    "- for interaction of non-linear affects, co-efficient for variable & variable squared & variable cubed, etc.\n",
    "\n",
    "- need to look at outliers, non-constant variance of error terms, high leverage points, collinearity\n",
    "\n",
    "\n",
    "When to use?\n",
    "- when there is a CLEAR relationship between two variables\n",
    "\n",
    "Examples?\n",
    "- money spent on ads vs sales\n",
    "- sales as a function of tv, radio and newspaper ads\n",
    "\n",
    "Choose: subset selection, lasso, least squares, generalized additive models, trees, bagging, boosting, support vector machines, thin plate splines\n",
    "\n",
    "How to determine which model to use?\n",
    "- Need to assess model accuracy. Use NEW data or test data to evaluate model. It is a bias vs variance tradeoff and depending on the situation, may want to make the tradeoff in different places.\n",
    "\n",
    "Classification\n",
    "- classification is about predicting a label and regression is about predicting a quantity \n",
    "- classification= eg. red/blue/green eg. above 10 dollars OR below 10 dollars eg. yes OR no\n",
    "- binary classification means classify into one of 2 variables, tertirary is three and so on\n",
    "- regression = sales of 100 dollars OR cost of 4 dollars \n",
    "\n",
    "- for 1/3 of classification problems, nearest neighbour gives the best fit\n",
    "- simple is usually better\n",
    "\n",
    "Least squares fit\n",
    "- total distance of all the points from the line to be the least possible\n",
    "\n",
    "- if 2 classification variables, use logistic regression to estimate probabilities NOT linear regression\n",
    "- if more than 2 classification variables, use multiclass logistic regression or discriminant analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R squared & Adjusted R squared\n",
    "- tells how good the line is compared to the average\n",
    "- Both R2 and the adjusted R2 give you an idea of how many data points fall within the line of the regression equation. However, there is one main difference between R2 and the adjusted R2: R2 assumes that every single variable explains the variation in the dependent variable. The adjusted R2 tells you the percentage of variation explained by only the independent variables that actually affect the dependent variable.\n",
    "- Both adjusted R-squared and predicted R-square provide information that helps you assess the number of predictors in your model:\n",
    "1- Use the adjusted R-square to compare models with different numbers of predictors\n",
    "2- Use the predicted R-square to determine how well the model predicts new observations and whether the model is too complicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis testing\n",
    "- t-statistic gives significance (is over 2 significant?); calculated by cooefficient divided by standard error; so not reject hypothesis test\n",
    "- p-value\n",
    "- accuracy of model by computing residual standard error\n",
    "- r squared (look at domain to get an idea if significant medicine 0.05 vs 0.6 in business\n",
    "- residual standard error\n",
    "- F-statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P value\n",
    "- common rule of thumb is p less than 0.05 is statistically significant\n",
    "- if you want to prove your drug works, you do so by showing the data is INCONSISTENT with the drug NOT working\n",
    "- important to limit false positives and false negatives\n",
    "- dont' care about p value for intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "- used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick. \n",
    "- uses a logistic function to model a binary dependent variable\n",
    "- create dummy variable for the variables with categories? Will choose a baseline and then put other dummy variables for that one variable into formula. Repeat for all other variables that have dummy variables.\n",
    "- in R, use glm() function\n",
    "- can be used with more than 1 variable\n",
    "- see correlations in variables\n",
    "- y hat is the predicted value\n",
    "- false positive or type 1 when predict going to happen but doesn't\n",
    "- false negative or type 2 is worse because predict not going to happen but does\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n",
    "- allows the visualization of the performance of an algorithm\n",
    "- acutal events are on diagonal and errors are on off-diagonal\n",
    "- false positive (type 1) are upper right and false negative are lower left (type 2)\n",
    "- accuracy rate = (total correct) / (all predictions)\n",
    "- error rate = (total wrong) / (all predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Co-efficients\n",
    "- have to say per unit\n",
    "- z score is (coefficient)/(std error) so standardized and can compare but maybe harder to interpret\n",
    "- can interpret coefficient signs eg pos contributes, neg detracts\n",
    "- cannot interpret magnitudes of the coefficients to quantify associations between the dependent variable and independent variables directly\n",
    "- can compare magnitudes of the coefficients to contrast level of per unit association of different IVs to the DV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminant analysis\n",
    "- bayes theorem for classification\n",
    "- good for when the classes are well separated whereas logistic regression is unstable\n",
    "- if n is small and the distribution if normal, the linear discriminant more stable than logistic regression\n",
    "- linear discriminat popular when we have more than 2 response classes because it also provides low dimensional views of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear discriminant analysis\n",
    "- measuring which centroid is closest\n",
    "- cannot carry out discriminate analysis if the numbers are very large so have to make modifications\n",
    "- logistic regression vs linear discriminant analysis. the difference is in how the parameters are estimated. LR uses conditional likelihood of y given x while LDA uses full likelihood of x and y.\n",
    "- logistic regression can also fit quadradictic boundaries by explicitly including quadratic terms in the model.\n",
    "-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n",
    "- tell how well did with determining correct response\n",
    "- the diagonal are the correct answers\n",
    "- Null Error Rate is how often you would be wrong if you always predicted the majority class\n",
    "- False positive rate are the fraction of negative examples that are classified as positive.\n",
    "- False negative rate are the fraction of positive examples that are classified as negative.\n",
    "- ROC curve with false positive rate on x axis and true positive rate on y axis.Want the curve as highest as possible in left hand corner. Receiver Operating Characteristics) curve\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "- popular (baseline) method for text categorization\n",
    "- advantages are very simple and easy to implement, needs less training data, handles both continuous and discrete data, highly scalable with number of predictors and data points, since it is fast then can be used in real time predictions, not sensitive to irrelevant features\n",
    "- in python for plots to show up inline, %matplotlib inline\n",
    "- need numpy, matplotlib.pyplot, seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "- main thing used for is to get an idea of the test set error of our model\n",
    "- separates the training and test set\n",
    "- cross validation done K times with K being the number of times the data is equally divided\n",
    "- eg. 5 fold cross validation is when there are 5 parts with 4 of them being the train and 1 being the validation; then keep alternating which part is the validation so come up with 5 models\n",
    "- leave one out cross validation is where leave out one of the training sets so 3 are training sets and 1 is validation. \n",
    "- better to choose K = 5 or 10 rather than LOOCV\n",
    "- the process for classification is the same as for quantitative problems\n",
    "- caution: if have 5000 predictors and pick best 100 predictors, cannot just apply cross validation. Must apply cross validation to both steps (so dont cherry pick variables).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap\n",
    "- used to quantify the uncertainty associated with a given estimator or statistical learning method\n",
    "- since unable to sample from the population to get new samples, apply bootstrap which samples from the data itself (which acts as population) with replacement (put the value back in sample after each time chosen)\n",
    "- then use these samples to get idea of variability\n",
    "- when sample in bootstrap, must figure out what parts of the data are independent\n",
    "- If NOT independent, do a block bootstrap which divides the data up into blocks and assumes the blocks are independent\n",
    "- bootstrap percentile confidence interval eg. look at the histrogram and take the values between 5% and 95% quantiles and this is the 90% confidence interval\n",
    "- very difficult to estimate prediction error for bootstrap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test vs Training error\n",
    "- the more fit data, the lower the training error but the test error will be higher because getting overfit\n",
    "- test error is the average error that results from using a new statistical learning method to predict the response on a new observation. Train error is calculated by applying the statistical learning method to the observations used in its training. But the two can be quite different. In particular, training dramatically underestimate test. Called bias-variance tradeoff.\n",
    "- Solution is to estimate test error by holding out a subset of the training observation from the fitting process and then applying the statistical learning method to those held out observations\n",
    "- validation-set approach - randomly divide avaiable set into training set and a validation (or hold out) set\n",
    "- model is fit on training set and the fitted model is used to predict the responses in validation set. The resulting validation-set erro provides and estimate of the test error. This is typically assessed using MSE in quatitative response and misclassification rate in qualitative response.\n",
    "- do up degree of polynomial vs mean squared error on y\n",
    "- cross validation to pick the best degree of polynomial and give an ideal of test error at end of fitting process\n",
    "- the more data, the better the fitting process and the less the error is\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
